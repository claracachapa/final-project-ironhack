{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning logic and code\n",
    "The idea is to create a recomendation system where the user is presented to a randomized set of artworks from which they can put a 'like' on. \n",
    "From the liked artworks will emerge other artworks with connections to the previous (e.g. same author, timeframe, wing, etc).\n",
    "\n",
    "However, since there is no user input, the machine learning model predicts whether an artwork from the MET is likely to be a highlight (i.e., a popular or significant piece) based on its attributes, such as medium, department, and historical context, serving as a baseline recommendation for users with no specific preferences. This model helps create a curated visit for individuals who want to experience the museum's most notable works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    full_df = pd.read_csv('../data/clean/full_dataset.csv', low_memory=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Helper function to process dates\n",
    "def process_date(date):\n",
    "    \"\"\"Converts date strings to numeric by averaging start and end years.\"\"\"\n",
    "    if isinstance(date, str):\n",
    "        try:\n",
    "            date = date.lower().replace('ca.', '').strip()\n",
    "            matches = re.findall(r'-?\\d+', date)\n",
    "            if len(matches) == 1:\n",
    "                return int(matches[0])\n",
    "            elif len(matches) == 2:\n",
    "                return (int(matches[0]) + int(matches[1])) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Preprocessing numeric and date features\n",
    "full_df['object_date_numeric'] = full_df['object_date'].apply(process_date)\n",
    "full_df['artist_begin_date_numeric'] = full_df['artist_begin_date'].apply(process_date)\n",
    "full_df['artist_end_date_numeric'] = full_df['artist_end_date'].apply(process_date)\n",
    "\n",
    "numerical_features = ['object_date_numeric', 'artist_begin_date_numeric', 'artist_end_date_numeric']\n",
    "categorical_features = ['medium', 'culture', 'period', 'classification', 'artist_nationality']\n",
    "text_features = ['title', 'object_name', 'tags']  # Include more text features\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for text features\n",
    "text_pipeline = TfidfVectorizer(max_features=500)\n",
    "\n",
    "# Fit transformers for each feature group\n",
    "numerical_data = numerical_pipeline.fit_transform(full_df[numerical_features])\n",
    "categorical_data = categorical_pipeline.fit_transform(full_df[categorical_features])\n",
    "text_data = text_pipeline.fit_transform(full_df['tags'])  # Example: using 'tags' for text\n",
    "\n",
    "# Concatenate the preprocessed data into a single matrix\n",
    "from scipy.sparse import hstack\n",
    "X_processed = hstack([numerical_data, categorical_data, text_data])\n",
    "\n",
    "# Function to recommend artworks based on user preferences\n",
    "def recommend_artworks(user_preferences, X_processed, full_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend artworks based on user preferences and similarity.\n",
    "    :param user_preferences: Dictionary of user inputs (e.g., style, artist, period).\n",
    "    :param top_n: Number of recommendations to return.\n",
    "    :return: DataFrame of recommended artworks.\n",
    "    \"\"\"\n",
    "    # Ensure all expected columns are in user_preferences\n",
    "    expected_columns = numerical_features + categorical_features + text_features\n",
    "    user_preferences_full = {col: user_preferences.get(col, None) for col in expected_columns}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    user_df = pd.DataFrame([user_preferences_full])\n",
    "\n",
    "    # Preprocess user input data (transform user input separately for each feature type)\n",
    "    numerical_user_data = numerical_pipeline.transform(user_df[numerical_features])\n",
    "    categorical_user_data = categorical_pipeline.transform(user_df[categorical_features])\n",
    "    text_user_data = text_pipeline.transform(user_df['tags'])  # Example: using 'tags' for text\n",
    "\n",
    "    # Concatenate the user data into a single vector\n",
    "    user_vector = hstack([numerical_user_data, categorical_user_data, text_user_data])\n",
    "\n",
    "    # Convert the user vector to dense format\n",
    "    user_vector_dense = user_vector.toarray()\n",
    "\n",
    "    # Convert all data vectors to dense format\n",
    "    all_data_vectors_dense = X_processed.toarray()\n",
    "\n",
    "    # Calculate cosine similarity between the user input and all artworks\n",
    "    similarity_scores = cosine_similarity(user_vector_dense, all_data_vectors_dense)\n",
    "\n",
    "    # Get top N recommendations\n",
    "    top_indices = np.argsort(similarity_scores[0])[::-1][:top_n]\n",
    "    return full_df.iloc[top_indices]\n",
    "\n",
    "# Function to recommend similar artworks based on liked artworks\n",
    "def recommend_similar_artworks(liked_artworks, all_data_vectors, full_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend artworks based on similarity to the liked artworks.\n",
    "    :param liked_artworks: DataFrame of artworks that the user likes.\n",
    "    :param all_data_vectors: Preprocessed data vectors of all artworks (sparse matrix).\n",
    "    :param full_df: Full DataFrame of artworks.\n",
    "    :param top_n: Number of artworks to recommend.\n",
    "    :return: DataFrame of recommended artworks.\n",
    "    \"\"\"\n",
    "    liked_indices = liked_artworks.index\n",
    "\n",
    "    # Initialize a set for all recommended artworks\n",
    "    recommended_indices = set()\n",
    "\n",
    "    # Convert the sparse matrix to dense array if needed for indexing\n",
    "    all_data_vectors_dense = all_data_vectors.toarray()  # Convert sparse matrix to dense\n",
    "\n",
    "    # Calculate similarity for each liked artwork\n",
    "    for idx in liked_indices:\n",
    "        # Reshape the vector for the current artwork to ensure it's 2D\n",
    "        current_artwork_vector = all_data_vectors_dense[idx].reshape(1, -1)\n",
    "        \n",
    "        # Calculate similarity with all other artworks (dense format)\n",
    "        similarities = cosine_similarity(current_artwork_vector, all_data_vectors_dense).flatten()\n",
    "        \n",
    "        # Get the top N similar artworks (excluding the artwork itself)\n",
    "        top_similar = np.argsort(similarities)[::-1][1:top_n+1]  # Exclude itself (index 0)\n",
    "        recommended_indices.update(top_similar)\n",
    "    \n",
    "    # Get the recommended artworks\n",
    "    return full_df.iloc[list(recommended_indices)].head(top_n)\n",
    "\n",
    "# Example user preferences (include all expected columns)\n",
    "user_preferences = {\n",
    "    'object_date_numeric': 1700,\n",
    "    'artist_begin_date_numeric': None,\n",
    "    'artist_end_date_numeric': None,\n",
    "    'medium': 'Oil on canvas',\n",
    "    'culture': 'European',\n",
    "    'classification': None,\n",
    "    'artist_nationality': None,\n",
    "    'tags': 'flowers',\n",
    "    'period': None,\n",
    "    'title': None,\n",
    "    'object_name': None\n",
    "}\n",
    "\n",
    "# Get initial recommendations based on user preferences\n",
    "recommended_artworks = recommend_artworks(user_preferences, X_processed, full_df, top_n=5)\n",
    "\n",
    "# Display the initial recommended artworks\n",
    "print(\"Initial Recommended Artworks based on User Preferences:\")\n",
    "print(recommended_artworks[['title', 'medium', 'culture', 'gallery_number', 'tags', 'image_url']])\n",
    "\n",
    "# Example: User likes certain artworks, so recommend similar ones\n",
    "liked_artworks = recommended_artworks  # Assume the user liked these artworks\n",
    "similar_artworks = recommend_similar_artworks(liked_artworks, X_processed, full_df, top_n=5)\n",
    "\n",
    "# Display similar artworks\n",
    "print(\"\\nSimilar Artworks to Liked Pieces:\")\n",
    "print(similar_artworks[['title', 'medium', 'culture', 'gallery_number', 'tags', 'image_url']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    full_df = pd.read_csv('../data/clean/full_dataset.csv', low_memory=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Helper function to process dates\n",
    "def process_date(date):\n",
    "    \"\"\"Converts date strings to numeric by averaging start and end years.\"\"\"\n",
    "    if isinstance(date, str):\n",
    "        try:\n",
    "            date = date.lower().replace('ca.', '').strip()\n",
    "            matches = re.findall(r'-?\\d+', date)\n",
    "            if len(matches) == 1:\n",
    "                return int(matches[0])\n",
    "            elif len(matches) == 2:\n",
    "                return (int(matches[0]) + int(matches[1])) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Preprocessing numeric and date features\n",
    "full_df['object_date_numeric'] = full_df['object_date'].apply(process_date)\n",
    "full_df['artist_begin_date_numeric'] = full_df['artist_begin_date'].apply(process_date)\n",
    "full_df['artist_end_date_numeric'] = full_df['artist_end_date'].apply(process_date)\n",
    "\n",
    "numerical_features = ['object_date_numeric', 'artist_begin_date_numeric', 'artist_end_date_numeric']\n",
    "categorical_features = ['medium', 'culture', 'period', 'classification', 'artist_nationality']\n",
    "text_features = ['tags', 'artist_display_name']  \n",
    "\n",
    "# Synthetic \"liked\" label creation (example rules based on your dataset)\n",
    "full_df['liked'] = (\n",
    "    (full_df['medium'] == 'Oil on canvas') |  # Liked if medium is Oil on canvas\n",
    "    (full_df['culture'] == 'European') |  # Liked if culture is European\n",
    "    (full_df['tags'].str.contains('flowers', na=False)) | # Liked if tags contain \"flowers\"\n",
    "    (full_df['period'] == 'Classical period')  \n",
    ").astype(int)  # Convert True/False to 1/0\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for text features\n",
    "text_pipeline = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "\n",
    "# Fit transformers for each feature group\n",
    "numerical_data = numerical_pipeline.fit_transform(full_df[numerical_features])\n",
    "categorical_data = categorical_pipeline.fit_transform(full_df[categorical_features])\n",
    "text_data = text_pipeline.fit_transform(full_df['tags'])  # Example: using 'tags' for text\n",
    "\n",
    "# Combine the processed data\n",
    "X_processed = hstack([numerical_data, categorical_data, text_data])\n",
    "y = full_df['liked']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    class_weight={0: 1, 1: 20},  \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis (optional)\n",
    "feature_importances = model.feature_importances_\n",
    "print(\"\\nTop Feature Importances:\")\n",
    "for idx, importance in enumerate(sorted(feature_importances, reverse=True)[:10]):\n",
    "    print(f\"Feature {idx + 1}: {importance:.4f}\")\n",
    "\n",
    "# Function to recommend artworks based on ML predictions\n",
    "def recommend_artworks_ml(X_processed, full_df, model, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend artworks based on the trained model predictions.\n",
    "    :param X_processed: Preprocessed feature matrix.\n",
    "    :param full_df: Full DataFrame of artworks.\n",
    "    :param model: Trained ML model.\n",
    "    :param top_n: Number of recommendations to return.\n",
    "    :return: DataFrame of recommended artworks.\n",
    "    \"\"\"\n",
    "    # Predict probabilities for all artworks\n",
    "    probabilities = model.predict_proba(X_processed)[:, 1]  # Get probabilities for \"liked\" class\n",
    "\n",
    "    # Get top N indices with highest probabilities\n",
    "    top_indices = np.argsort(probabilities)[::-1][:top_n]\n",
    "\n",
    "    # Return the top recommended artworks\n",
    "    return full_df.iloc[top_indices]\n",
    "\n",
    "# Get recommendations using the trained ML model\n",
    "recommended_artworks_ml = recommend_artworks_ml(X_processed, full_df, model, top_n=5)\n",
    "\n",
    "# Display recommended artworks\n",
    "print(\"\\nRecommended Artworks Based on ML Predictions:\")\n",
    "print(recommended_artworks_ml[['title', 'medium', 'culture', 'tags']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
